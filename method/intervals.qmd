---
title: "Intervals"
description: |
  Confidence, credible and prediction intervals
author: "Chi Zhang"
date: "2024-02-24"
categories: [Inference]
sidebar: false
code-block-bg: true
code-block-border-left: true
format: 
  html:
    toc: true
    toc-depth: 3
    code-fold: false
    code-tools: false

---

Key difference: confidence and credible intervals: about the (unknown) **parameter**; prediction interval: about individual (unseen) **observations**.



## Confidence vs credible interval


Confidence interval (frequentist), about the unknown but fixed parameter. That means, the parameter is not treated as a random variable so does not have a probability distribution. CI is random because it is based on your sample.

Credible interval (Bayesian), associated with posterior distribution of the parameter. The parameter is treated as a random variable hence has a probability distribution.




## Prediction intereval

In a regression model, you might want to know both confidence and prediction intervals.

* CI for mean value of $y$ when $x =0$, the **mean** response (e.g. growth of GDP), this is a parameter, an average
* PI for $y$ when $x=0$, this is an individual observation.



### In simple linear regression

Standard deviation for linear predictor $\alpha + \beta x$ is 

$\hat{\sigma}_{linpred} = \hat{\sigma} \sqrt{\frac{1}{n} + \frac{(x_{new} - \bar{x})^2}{\sum(x_i - \bar{x})}}$



Confidence interval

$\hat{y_{new}} \pm t_{1-\frac{\alpha}{2}, n-2} \times \sqrt{\hat{\sigma}^2 (\frac{1}{n} + \frac{(x_{new} - \bar{x})^2}{\sum(x_i - \bar{x})^2})}$


Standard deviation for the predicted value $\alpha + \beta x + \epsilon$ is

$\hat{\sigma}_{prediction} = \hat{\sigma} \sqrt{1 + \frac{1}{n} + \frac{(x_{new} - \bar{x})^2}{\sum(x_i - \bar{x})}}$


Prediction interval (frequentist)

$\hat{y_{new}} \pm t_{1-\frac{\alpha}{2}, n-2} \times \sqrt{\hat{\sigma}^2 (1 + \frac{1}{n} + \frac{(x_{new} - \bar{x})^2}{\sum(x_i - \bar{x})^2})}$






## Posterior predictive distribution 

Difference between **posterior distribution** and **posterior predictive distribution** PPD

* posterior dist $p(\theta|x) = c \times p(x|\theta)p(\theta)$, depends on the parameter $\theta$
* PPD does not depend on $\theta$ as it is integrated out, for unobserved $x^*$, 

$p(x^*|x) = \int_{\Theta} c \times p(x^*, \theta|x) d\theta = \int_{\Theta} c \times p(x^*|\theta)p(\theta|x) d\theta$

PD is part of PPD formulation.

* PD explains the unknown parameter (treated as a random variable), conditional on the evidence observed (data).
* PPD is the distribution for the future predicted data based on the data you have already seen.




# Example: Mortality 

We explore the all-cause mortality counts in Norway between 2000 to 2023. More specifically, we use year 2000-2019 (pre-pandemic years) to fit a simple linear regression model, and predict the expected number of deaths post pandemic (2020-2023). I include both frequentist approach with `lm`, and Bayesian approach with `rstanarm::stan_glm`. 

The data of mortality example comes from [Statistics Norway](https://www.ssb.no/en/befolkning/fodte-og-dode/statistikk/dode) and is publicly available.


```{r}
#| label: data
#| echo: true
#| eval: true

library(ggplot2)
library(patchwork)
library(data.table)
# load data 
mortality <- readRDS("data/mortality_2000_2023.rds")

# select only total age group
d <- mortality[age == '000_059']
d
```


## Explore the data

```{r}
#| label: eda
#| echo: true
#| eval: true
#| code-fold: true
#| code-summary: "Show the code"

q1 <- ggplot(d, aes(x = year, y = deaths_n, group))
q1 <- q1 + geom_line()
q1 <- q1 + geom_point(size = 2)
q1 <- q1 + geom_vline(xintercept = 2019.5, color = "red", lty = 2)
q1 <- q1 + theme_bw()
q1 <- q1 + scale_x_continuous(breaks = seq(2000, 2023, 2))
q1 <- q1 + labs(
  x = 'Year', 
  y = 'Number of deaths', 
  title = 'Number of death in Norway \n2000 - 2023'
)
q1 <- q1 + theme(
  axis.text = element_text(size = 11),
  axis.title = element_text(size = 12), 
  plot.title = element_text(size = 12), 
  axis.text.x = element_text(angle = 45, vjust = 0.5) 
)
# q1

# per 100k
q2 <- ggplot(d, aes(x = year, y = deaths_vs_pop_per_100k))
q2 <- q2 + geom_line()
q2 <- q2 + geom_point(size = 2)
q2 <- q2 + geom_vline(xintercept = 2019.5, color = "red", lty = 2)
q2 <- q2 + theme_bw()
q2 <- q2 + scale_x_continuous(breaks = seq(2000, 2023, 2))
q2 <- q2 + labs(
  x = 'Year', 
  y = 'Number of deaths', 
  title = 'Number of death in Norway \n(per 100k population) 2000 - 2023'
)
q2 <- q2 + theme(
  axis.text = element_text(size = 11),
  axis.title = element_text(size = 12), 
  plot.title = element_text(size = 12), 
  axis.text.x = element_text(angle = 45, vjust = 0.5) 
)
# plot side by side
q1 + q2
```



## Model mortality using 2000-2019 data

```{r}
#| label: model
#| echo: true
#| eval: true

# take pre 2019 data
dt <- d[year <= 2019, .(year, deaths_vs_pop_per_100k)]

# prediction 
dnew <- data.frame(year = c(2020, 2021, 2022, 2023))

```



### Linear regression with `lm`

```{r}
#| label: cipi
#| echo: true
#| eval: true

m_linear <- lm(deaths_vs_pop_per_100k ~ year, 
               data = dt)

# summary(m_linear)

# produce two intervals
pred_freq_pi <- predict(m_linear, newdata = dnew, interval = 'prediction')
pred_freq_ci <- predict(m_linear, newdata = dnew, interval = 'confidence')
```


#### Verify from formula 

```{r}
#| label: cipi-formula
#| echo: true
#| eval: true


# verify with formula
n <- nrow(dt)

# option 1
fitted_val <- m_linear$fitted.values
mse <- sum((dt$deaths_vs_pop_per_100k - fitted_val)^2)/(n-2)
mse
# option 2
sum((m_linear$residuals)^2)/(n-2)

# option 3
summary(m_linear)$sigma^2

# option 4
dvmisc::get_mse(m_linear)


# t-val
tval <- qt(p=0.975, df=n-2)
mean_x <- mean(dt$year)

# sum(xi - xbar)^2
ssx <- sum((dt$year - mean_x)^2)

sd_confint <- sqrt(mse * (1/20+ ((dnew$year - mean_x)^2)/ssx))
sd_predint <- sqrt(mse * (1 + 1/20+ ((dnew$year - mean_x)^2)/ssx))


# point prediction
b0 <- coef(m_linear)[1]
b <- coef(m_linear)[2]
prednew <- b0 + b*dnew$year
prednew

# prediction interval
predint_linear <- data.frame(fit = prednew, 
                             lwr = prednew - tval*sd_predint, 
                             upr = prednew + tval*sd_predint)

predint_linear
pred_freq_pi # compare with result from lm

# confidence interval
confint_linear <- data.frame(fit = prednew, 
                             lwr = prednew - tval*sd_confint, 
                             upr = prednew + tval*sd_confint)

confint_linear
pred_freq_ci # compare with result from lm
```



### Linear regression with `rstanarm`



```{r}
#| label: m-bayes
#| echo: true
#| eval: true

m_bayes <- rstanarm::stan_glm(
  deaths_vs_pop_per_100k ~ year, 
  data = dt, 
  family = gaussian,
  iter = 2000,
  chains = 8,
  refresh = 0
)

m_bayes 
```



```{r}
#| label: result-mbayes
#| echo: true
#| eval: false

sims <- as.matrix(m_bayes)
median <- apply(sims, 2, median)
median
mad_sd <- apply(sims, 2, mad) 
# median absolute deviation (similar to sd)
mad_sd
```

#### Credible interval

```{r}
#| label: credible-int
#| echo: true
#| eval: true

# credible interval about the fit
cred <- rstanarm::posterior_interval(m_bayes, prob = 0.95)
cred

# equivalent to
sims <- as.matrix(m_bayes)
apply(sims, 2, quantile, probs = c(0.025, 0.5, 0.975))
```


### Point prediction


```{r}
#| label: point-pred
#| echo: true
#| eval: true


# point predict
# uses median from the posterior sim
y_point_pred <- predict(m_bayes, newdata = dnew)
y_point_pred

a_hat <- coef(m_bayes)[1] # median
b_hat <- coef(m_bayes)[2] # median
a_hat + b_hat*dnew$year

```

### Uncertainty of linear predictor

The uncertainty of linear predictor, $a + bx$ is propagated through the uncertainty in $a$ and $b$, respectively. For now the error term is not included. 

`rstanarm::posterior_linpred` is equivalent to using each pairs of $a, b$ from the posterior distribution to compute the point predictions.

```{r}
#| label: linpred
#| echo: true
#| eval: true

# linear predictor with uncertainty via a's and b's
y_linpred <- rstanarm::posterior_linpred(m_bayes, newdata = dnew)
head(y_linpred)

# focus on one year: 2023
hist(y_linpred[, 4], main = 'Predictions for 2023')

head(y_linpred[, 4])
y_linpred_byhand <- sims[,1] + dnew$year[4] * sims[,2]
y_linpred_byhand[1:6]
```

### Posterior predictive distribution

With PPD, include the additional uncertainty in $\sigma$. This is equivalent to using the linear predictor from above, plus a random draw from `rnorm(1, 0, sigma)`.

Due to randomness in the error, we can not get the exact same results. But they should be close enough.

```{r}
#| label: ppd
#| echo: true
#| eval: true

# posterior predictive dist (with sigma)
y_postpred <- rstanarm::posterior_predict(m_bayes, newdata = dnew)
head(y_postpred)


# by hand
# focus on one year: 2023
n_sim <- nrow(sims)
y_postpred_byhand <- y_linpred_byhand + rnorm(n_sim, 0, sims[,3])
par(mfrow = c(1,2))
hist(y_postpred_byhand, main = 'PPD for 2023 (linpred + error)')
hist(y_postpred[,4], main = 'PPD for 2023 (post_predict)')

y_postpred[,4] |> summary()
y_postpred_byhand |> summary()
```




## Prediction for 2020-2023 mortality

Here we choose to use `rstanarm::posterior_predict()`.

```{r}
#| label: final-prediction
#| echo: true
#| eval: true

pred_all <- rstanarm::posterior_predict(m_bayes, d)

pred_all_quantile <- apply(pred_all, 2, quantile, 
                    probs = c(0.025, 0.5, 0.975)) |> 
  t()  |> 
  as.data.frame()
pred_all_quantile[21:24,]
```


We can compare with the frequentist prediction interval, and we see that they are very close.

```{r}
#| label: lm-predint
#| echo: true
#| eval: true

predint_linear
```


## Visualize mortality prediction

```{r}
#| label: final-prediction-plot
#| echo: true
#| eval: true
#| code-fold: true
#| code-summary: "Show the code"

pd <- copy(d)
# head(pd)
pd <- cbind(pd, pred_all_quantile)

setnames(pd, old = '2.5%', new = 'exp_death_per100k_025')
setnames(pd, old = '50%', new = 'exp_death_per100k_50')
setnames(pd, old = '97.5%', new = 'exp_death_per100k_975')

# also compute the expected death overall

pd[, exp_death_025 := exp_death_per100k_025 * pop_jan1_n/100000]
pd[, exp_death_50 := exp_death_per100k_50 * pop_jan1_n/100000]
pd[, exp_death_975 := exp_death_per100k_975 * pop_jan1_n/100000]

pd[, alert := fcase(
  deaths_vs_pop_per_100k > exp_death_per100k_975, "Higher than expected",
  default = "Expected"
)]

pd[, type := fcase(
  year <= 2019, paste0("Baseline (2000-2019)"),
  default = "Pandemic years (2020-2023)"
)]


# make plot
q <- ggplot(pd, aes(x = year))
q <- q + geom_ribbon(mapping = aes(ymin = exp_death_per100k_025, 
                                   ymax = exp_death_per100k_975), 
                     alpha = 0.3)
q <- q + geom_line(mapping = aes(y = exp_death_per100k_50, lty = type), linewidth = 1)
q <- q + geom_point(mapping = aes(y = deaths_vs_pop_per_100k, color = alert), size = 3)
q <- q + geom_vline(xintercept = 2019.5, color = "red", lty = 2)
q <- q + expand_limits(y=0)
q <- q + scale_y_continuous("Number of death per 100k", expand = expansion(mult = c(0, 0.1)))
q <- q + scale_x_continuous("Year", breaks = seq(2000, 2023, 2))
q <- q + scale_linetype_discrete(NULL)
q <- q + scale_color_brewer(NULL, palette = "Set1", direction = -1)
q <- q + theme_bw()
q <- q + theme(
  axis.text = element_text(size = 11),
  axis.title = element_text(size = 12), 
  plot.title = element_text(size = 15), 
  axis.text.x = element_text(angle = 45, vjust = 0.5) 
)
q <- q + theme(legend.position = "bottom", legend.direction = "horizontal")
q <- q + theme(legend.box = "horizontal", legend.margin = margin(2, 2, 2, 2))
q
```





# Reference 


* A very good decomposition of prediction interval in linear regression: [Post by Bryan Shalloway](https://www.bryanshalloway.com/2021/03/18/intuition-on-uncertainty-of-predictions-introduction-to-prediction-intervals/)
* Blog by Professor Rob Hyndman on [difference between prediction intervals and confidence intervals](https://robjhyndman.com/hyndsight/intervals/)
* The data of mortality example comes from [Statistics Norway](https://www.ssb.no/en/befolkning/fodte-og-dode/statistikk/dode) and is publicly available.





